{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfa43f6-796a-44cc-8ba2-a99734a33ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('names.txt', 'r') as f:\n",
    "    names = f.read().split('\\n')\n",
    "\n",
    "names[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fba5bf4-a5d0-45e4-b4e4-17827175a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13ae3d8-a290-45b5-ad3e-d61e5c1aaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = []\n",
    "for name in names:\n",
    "    vocab += name\n",
    "vocab = sorted(set(vocab))\n",
    "\n",
    "# Build mapping from letter to integer id and for id to letter\n",
    "itos = { i+1:l for i, l in enumerate(vocab)}\n",
    "# Additional `point` at index 0\n",
    "itos[0] = '.'\n",
    "stoi = { l:i for i, l in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f3a678f-43cb-4668-9380-4241f1a61c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataset\n",
    "import torch\n",
    "\n",
    "# Context lenght -> How many characters we take to predict the next\n",
    "block_size = 3\n",
    "\n",
    "# Inputs\n",
    "X = []\n",
    "# Targets\n",
    "Y = []\n",
    "\n",
    "# For each name\n",
    "for word in names:\n",
    "    # The start is an empty new context (which contains our designed dot special character)\n",
    "    context = [0] * block_size\n",
    "    # For each character in the name (adding dot as a stopping token)\n",
    "    for ch in word + '.':\n",
    "        # We add the current context and as an input to the dataset\n",
    "        X.append(context)\n",
    "        # Get the index of the current character and add it as a target for a potential\n",
    "        # generated new character that could follow this context\n",
    "        idx_ch = stoi[ch]\n",
    "        Y.append(idx_ch)\n",
    "        # Slide the context window and add the new character to it\n",
    "        context = context[1:] + [idx_ch]\n",
    "\n",
    "# View demo of dataset\n",
    "def dataset_demo():\n",
    "    for i, p in zip(X[:20], Y[:20]):\n",
    "        print([itos[c] for c in i], \"-->\", itos[p])\n",
    "\n",
    "    \n",
    "X = torch.Tensor(X)\n",
    "Y = torch.Tensor(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
