{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3494f353-6285-4eaa-9f01-f723ee31e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "random.seed(0x1337_b00b)\n",
    "\n",
    "# Context length -> How many characters we take to predict the next\n",
    "block_size = 3\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        with open('names.txt', 'r') as f:\n",
    "            names = f.read().split('\\n')\n",
    "        self.names = names\n",
    "\n",
    "        self.build_vocab()\n",
    "\n",
    "        # Shuffle names in place\n",
    "        random.shuffle(self.names)\n",
    "        # Training set and dev/validation set last index\n",
    "        train_set_idx = int(0.8 * len(names))\n",
    "        validation_idx = int(0.9 * len(names))\n",
    "        \n",
    "        self.X, self.Y = {}, {}\n",
    "        self.X[\"train\"], self.Y[\"train\"] = self.build_dataset(self.names[:train_set_idx])\n",
    "        self.X[\"valid\"], self.Y[\"valid\"] = self.build_dataset(self.names[train_set_idx:validation_idx])\n",
    "        self.X[\"test\"], self.Y[\"test\"] = self.build_dataset(self.names[validation_idx:])\n",
    "        \n",
    "\n",
    "    def build_vocab(self):\n",
    "        # Build vocabulary\n",
    "        vocab = []\n",
    "        for name in self.names:\n",
    "            vocab += name\n",
    "        self.vocab = sorted(set(vocab))\n",
    "        \n",
    "        # Build mapping from letter to integer id and for id to letter\n",
    "        self.itos = { i+1:l for i, l in enumerate(self.vocab)}\n",
    "        # Additional `point` at index 0\n",
    "        self.itos[0] = '.'\n",
    "        self.stoi = { l:i for i, l in self.itos.items()}\n",
    "                \n",
    "\n",
    "    def build_dataset(self, words):\n",
    "        global block_size\n",
    "        # Inputs\n",
    "        X = []\n",
    "        # Targets\n",
    "        Y = []\n",
    "        \n",
    "        # For each name\n",
    "        for word in words:\n",
    "            # The start is an empty new context (which contains our designed dot special character)\n",
    "            context = [0] * block_size\n",
    "            # For each character in the name (adding dot as a stopping token)\n",
    "            for ch in word + '.':\n",
    "                # We add the current context and as an input to the dataset\n",
    "                X.append(context)\n",
    "                # Get the index of the current character and add it as a target for a potential\n",
    "                # generated new character that could follow this context\n",
    "                idx_ch = self.stoi[ch]\n",
    "                Y.append(idx_ch)\n",
    "                # Slide the context window and add the new character to it\n",
    "                context = context[1:] + [idx_ch]\n",
    "    \n",
    "        X = torch.Tensor(X).long()\n",
    "        Y = torch.Tensor(Y).long()\n",
    "        return (X, Y)\n",
    "\n",
    "\n",
    "    def dataset_demo(self, split, count = 10):\n",
    "        for i, p in zip(self.X[split][:count], self.Y[split][:count]):\n",
    "            print([self.itos[c.item()] for c in i], \"-->\", self.itos[p.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3411d5ee-8a06-4ab1-8e64-965643d08786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples\n",
      "['.', '.', '.'] --> t\n",
      "['.', '.', 't'] --> e\n",
      "['.', 't', 'e'] --> n\n",
      "['t', 'e', 'n'] --> s\n",
      "['e', 'n', 's'] --> l\n",
      "['n', 's', 'l'] --> e\n",
      "['s', 'l', 'e'] --> y\n",
      "['l', 'e', 'y'] --> .\n",
      "['.', '.', '.'] --> k\n",
      "['.', '.', 'k'] --> e\n",
      "Valid examples\n",
      "['.', '.', '.'] --> k\n",
      "['.', '.', 'k'] --> e\n",
      "['.', 'k', 'e'] --> e\n",
      "['k', 'e', 'e'] --> g\n",
      "['e', 'e', 'g'] --> e\n",
      "['e', 'g', 'e'] --> n\n",
      "['g', 'e', 'n'] --> .\n",
      "['.', '.', '.'] --> l\n",
      "['.', '.', 'l'] --> o\n",
      "['.', 'l', 'o'] --> l\n",
      "Test examples\n",
      "['.', '.', '.'] --> d\n",
      "['.', '.', 'd'] --> a\n",
      "['.', 'd', 'a'] --> x\n",
      "['d', 'a', 'x'] --> o\n",
      "['a', 'x', 'o'] --> n\n",
      "['x', 'o', 'n'] --> .\n",
      "['.', '.', '.'] --> a\n",
      "['.', '.', 'a'] --> o\n",
      "['.', 'a', 'o'] --> i\n",
      "['a', 'o', 'i'] --> .\n"
     ]
    }
   ],
   "source": [
    "d = Dataset()\n",
    "print(\"Train examples\")\n",
    "d.dataset_demo(\"train\")\n",
    "print(\"Valid examples\")\n",
    "d.dataset_demo(\"valid\")\n",
    "print(\"Test examples\")\n",
    "d.dataset_demo(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0baed8cf-701f-448a-b709-c2295396b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters setup\n",
    "from torch.nn import functional as F\n",
    "\n",
    "emb_size = 10\n",
    "g = torch.Generator().manual_seed(0x1337_b00b)\n",
    "# Create the embedding\n",
    "C = torch.randn((27, emb_size), generator=g)\n",
    "\n",
    "# Initializing the model parameters\n",
    "# First layer\n",
    "W1 = torch.randn((3 * emb_size, 200), generator=g)\n",
    "b1 = torch.randn(200, generator=g)\n",
    "# Second layer\n",
    "# We multiply by 0.01 (or a small scalar) in order to reduce and more uniformly\n",
    "# distribute the weights for the first training pass and loss calculation, such that\n",
    "# the logits that we get at the end of the network given roughly the same probability\n",
    "# to any of the characters\n",
    "W2 = torch.randn((200, 27), generator=g) * 0.01\n",
    "# We multiply by zero to make sure intialization give uniform distribution to the logits\n",
    "b2 = torch.randn(27, generator=g) * 0\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "param_count = sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b759e842-528e-475b-9839-a16957d06efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "steps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8f8f9d9-f3e7-421d-93a0-72400bfb9593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 / 200000 -> 3.3197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3197, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "max_steps = 200000\n",
    "for idx in range(max_steps):\n",
    "    # Minibatch construction\n",
    "    # Sample indexes from X (minibatch of 32 examples)\n",
    "    idxs = torch.randint(0, d.X[\"train\"].shape[0], (32,))\n",
    "    \n",
    "    # Forward pass, only with the minibatch\n",
    "    emb = C[d.X[\"train\"][idxs]]\n",
    "    hpreact = emb.view(emb.shape[0], 3 * emb_size) @ W1 + b1\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2 # log-counts\n",
    "    # Compute the loss\n",
    "    loss = F.cross_entropy(logits, d.Y[\"train\"][idxs])\n",
    "    #print(loss.item())\n",
    "    # Reset the gradients\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    # Compute the backward pass\n",
    "    loss.backward()\n",
    "    # Gradually increase the learning rate in each step\n",
    "    # lr = lrs[idx]\n",
    "    lr = 0.1 if idx < 100000 else 0.01\n",
    "    # Update / nudge the value in the direction of the gradietn\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # Track progress\n",
    "    # lrs_used.append(lr_exponents[idx])\n",
    "    steps.append(idx)\n",
    "    # Each 10k steps print the progress of the loss\n",
    "    if idx % 10000 == 0:\n",
    "        print(f\"{idx:6d} / {max_steps:6d} -> {loss.item():.4f}\")\n",
    "    losses.append(loss.log10().item())\n",
    "\n",
    "    break\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f34f6577-d055-48e1-9b5d-203a6e52eea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2221.,  142.,  104.,   54.,   69.,   45.,   35.,   31.,   35.,\n",
       "          27.,   22.,   24.,   28.,   19.,   30.,   32.,   22.,   21.,\n",
       "          29.,   20.,   19.,   22.,   21.,   12.,    9.,   21.,   24.,\n",
       "          23.,   24.,   16.,   15.,   20.,   17.,   26.,   30.,   24.,\n",
       "          19.,   31.,   30.,   24.,   22.,   26.,   20.,   47.,   52.,\n",
       "          57.,   76.,   85.,  164., 2414.]),\n",
       " array([-1.  , -0.96, -0.92, -0.88, -0.84, -0.8 , -0.76, -0.72, -0.68,\n",
       "        -0.64, -0.6 , -0.56, -0.52, -0.48, -0.44, -0.4 , -0.36, -0.32,\n",
       "        -0.28, -0.24, -0.2 , -0.16, -0.12, -0.08, -0.04,  0.  ,  0.04,\n",
       "         0.08,  0.12,  0.16,  0.2 ,  0.24,  0.28,  0.32,  0.36,  0.4 ,\n",
       "         0.44,  0.48,  0.52,  0.56,  0.6 ,  0.64,  0.68,  0.72,  0.76,\n",
       "         0.8 ,  0.84,  0.88,  0.92,  0.96,  1.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(h.view(-1).tolist(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6343b3b-6fea-48cf-9594-8853da32694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h.view(-1).tolist(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cae342ea-e167-4c1e-b0c0-0b571e04707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, 2.0383141040802\n",
      "valid, 2.121753454208374\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_loss(split='train'):\n",
    "    # Loss over the entire training set\n",
    "    emb = C[d.X[split]]\n",
    "    h = torch.tanh(emb.view(emb.shape[0], 3*emb_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2 # log-counts\n",
    "    # Compute the loss\n",
    "    loss = F.cross_entropy(logits, d.Y[split])\n",
    "    \n",
    "    print(f\"{split}, {loss}\")\n",
    "\n",
    "compute_loss()\n",
    "compute_loss('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46fb9aca-862b-447a-bdaf-d4b4c64cf8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phira.\n",
      "asite.\n",
      "shaubriggamani.\n",
      "dashtily.\n",
      "aas.\n",
      "mercerton.\n",
      "kalifynn.\n",
      "jalane.\n",
      "er.\n",
      "nelyn.\n",
      "majsinda.\n",
      "ani.\n",
      "kahi.\n",
      "avin.\n",
      "yimanon.\n",
      "lulis.\n",
      "jahemiya.\n",
      "cailarnslyn.\n",
      "somyah.\n",
      "kena.\n"
     ]
    }
   ],
   "source": [
    "# Sampling from the model\n",
    "\n",
    "for i in range(20):\n",
    "    # Storage for the characters\n",
    "    out = []\n",
    "    # initial context\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[context]\n",
    "        h = torch.tanh(emb.view(1, block_size * emb_size) @ W1 + b1)\n",
    "        logits = h @ W2 + b2 # log-counts\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # Sample from the probabilities\n",
    "        idx = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        if idx == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join([d.itos[o] for o in out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea2f92-e508-4d2e-99e7-9e2d04ad09fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
